{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_validate\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as  plt\n",
    "%matplotlib inline\n",
    "\n",
    "defenders = pd.read_csv(r'C:\\Users\\sosan\\Documents\\Dissertation\\DataSets\\Fifa 20\\TransformedData\\Defenders.csv')\n",
    "defenders.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defenders.columns[28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Missing(data):\n",
    "    \"\"\" Identify missing values in the dataframe\n",
    "    :param data: set the font to be used for the labels, legend and axes\n",
    "    \"\"\"\n",
    "    total = data.isnull().sum().sort_values(ascending = False)\n",
    "    percent = round(data.isnull().sum().sort_values(ascending = False)/len(data)*100, 2)\n",
    "    missing = pd.concat([total, percent], axis = 1,keys= ['Total', 'Percent'])\n",
    "    return(missing) \n",
    "\n",
    "#plots number of dataframes side by side\n",
    "def SideSide(*args):\n",
    "    html_str=''\n",
    "    for df in args:\n",
    "        html_str+=df.to_html()\n",
    "    display_html(html_str.replace('table','table style=\"display:inline\"'),raw = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_Defender_Data = Missing(defenders)\n",
    "missing_Defender_Data\n",
    "#missing_Defender_Data.to_csv(r'C:\\Users\\sosan\\Documents\\Dissertation\\DataSets\\Fifa 20\\TransformedData\\MissingDataResult.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defenders.loc[defenders['BP'] == 'CB', 'BP'] = 0\n",
    "defenders.loc[(defenders['BP'] == 'LB') | (defenders['BP'] == 'LWB'), 'BP'] = 1\n",
    "defenders.loc[(defenders['BP'] == 'RB') | (defenders['BP'] == 'RWB'), 'BP'] = 2\n",
    "defenders['BP'].head(10)\n",
    "\n",
    "defenders.loc[defenders['foot'] == 'Right', 'foot'] = 1\n",
    "defenders.loc[defenders['foot'] == 'Left', 'foot'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "indexes = defenders._get_numeric_data().columns\n",
    "print(indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defending_features = ['Age', 'Overall', 'Potential', 'Height', 'Weight', 'BOV', 'Growth',\n",
    "       'Value', 'Wage', 'Release Clause', 'Attacking', 'Crossing', 'Finishing',\n",
    "       'Heading Accuracy', 'Short Passing', 'Volleys', 'Skill', 'Dribbling',\n",
    "       'Curve', 'FK Accuracy', 'Long Passing', 'Ball Control', 'Movement',\n",
    "       'Acceleration', 'Sprint Speed', 'Agility', 'Reactions', 'Balance',\n",
    "       'Power', 'Shot Power', 'Jumping', 'Stamina', 'Strength', 'Long Shots',\n",
    "       'Mentality', 'Aggression', 'Interceptions', 'Positioning', 'Vision',\n",
    "       'Penalties', 'Composure', 'Defending', 'Marking', 'Standing Tackle',\n",
    "       'Sliding Tackle', 'Goalkeeping', 'GK Diving', 'GK Handling',\n",
    "       'GK Kicking', 'GK Positioning', 'GK Reflexes', 'Total Stats',\n",
    "       'Base Stats', 'W/F', 'SM', 'IR', 'PAC', 'SHO', 'PAS', 'DRI', 'DEF',\n",
    "       'PHY']\n",
    "defenders[defending_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defenders = defenders[(defenders['BP'] != 'CB')]\n",
    "\n",
    "\n",
    "\n",
    "defenders = defenders[['Age','BP', 'Overall','foot', 'Potential', 'Height', 'Weight', 'BOV',\n",
    "       'Growth', 'Value', 'Wage', 'Release Clause', 'Attacking', 'Crossing',\n",
    "       'Finishing', 'Heading Accuracy', 'Short Passing', 'Volleys', 'Skill',\n",
    "       'Dribbling', 'Curve', 'FK Accuracy', 'Long Passing', 'Ball Control',\n",
    "       'Movement', 'Acceleration', 'Sprint Speed', 'Agility', 'Reactions',\n",
    "       'Balance', 'Power', 'Shot Power', 'Jumping', 'Stamina', 'Strength',\n",
    "       'Long Shots', 'Mentality', 'Aggression', 'Interceptions', 'Positioning',\n",
    "       'Vision', 'Penalties', 'Composure', 'Defending', 'Marking',\n",
    "       'Standing Tackle', 'Sliding Tackle', 'Goalkeeping', 'GK Diving',\n",
    "       'GK Handling', 'GK Kicking', 'GK Positioning', 'GK Reflexes',\n",
    "       'Total Stats', 'Base Stats', 'W/F', 'SM', 'IR', 'PAC', 'SHO', 'PAS',\n",
    "       'DRI', 'DEF', 'PHY']]\n",
    "\n",
    "min_max = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defenders[defending_features] =  min_max.fit_transform(defenders[defending_features])\n",
    "#df_scaled = pd.DataFrame(player, columns=numerical_Data.columns,index=numerical_Data.index)\n",
    "defenders.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DataFrame_Correlation_matrix = defenders.corr()\n",
    "print(DataFrame_Correlation_matrix['Overall'].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictorFeatures = defenders.columns.drop(['Overall', 'BP'])\n",
    "defenders['foot'] = defenders['foot'].astype(int)\n",
    "x_variable, y_variable = defenders[predictorFeatures], defenders.BP.astype(int)\n",
    "x_variable.iloc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_variable.iloc[1:6, 6:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_variable = y_variable.astype(int)\n",
    "y_variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_variable, y_variable, test_size=0.2)\n",
    "print (x_train.shape, y_train.shape)\n",
    "print (x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.columns[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import *\n",
    "\n",
    "#Learning curve\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "# Import Classifiers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "#import plotter\n",
    "import seaborn as sns\n",
    "\n",
    "classes = ['Center Back','Left Wing-Back', 'Right Wing-Back']\n",
    "\n",
    "def Apply_model(model, x_data, y_true, cv_folds = 5):\n",
    "\n",
    "    y_pred = model.predict(x_data)\n",
    "\n",
    "    Accuracy = round(np.median(cross_val_score(model, x_data, y_true, cv = cv_folds)),2)*100\n",
    "    \n",
    "    Error   = 1 - Accuracy\n",
    "    \n",
    "    precision = precision_score(y_true, y_pred, average='micro') * 100\n",
    "    \n",
    "    recall = recall_score(y_true, y_pred, average = 'micro') * 100\n",
    "    \n",
    "    f1score = f1_score(y_true, y_pred, average = 'micro') * 100\n",
    "\n",
    "    print('Model Name: ',type(model) )\n",
    "    #print(\"score = \", RF_Model.score(x_train, y_train), \"\\n\")\n",
    "\n",
    "    print('Scoring Accuracy: %.2f %%'%(Accuracy))\n",
    "    print(\"Precision: %.2f %%\"%(precision))\n",
    "    print(\"Recall: %.2f %%\"%(recall))\n",
    "    print('f1-score: %.2f %%'%(f1score))\n",
    "    return y_pred\n",
    "\n",
    "def Confuse(y, y_pred, classes):\n",
    "\n",
    "    training_con_matrix = confusion_matrix(y, y_pred)\n",
    "    print(training_con_matrix)\n",
    "\n",
    "    cnf_matrix = confusion_matrix(y, y_pred)\n",
    "    \n",
    "    cnf_matrix = cnf_matrix.astype('float') / cnf_matrix.sum(axis = 1)[:, np.newaxis]\n",
    "    c_train = pd.DataFrame(cnf_matrix, index = classes, columns = classes)\n",
    "\n",
    "    cmap = sns.diverging_palette( 220 , 10 , as_cmap = True )\n",
    "\n",
    "    ax = sns.heatmap(c_train, annot = True, cmap = cmap, square = True, cbar = False, \n",
    "                          fmt = '.2f', annot_kws = {\"size\": 20})\n",
    "    return(ax, c_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "modelList = [RandomForestClassifier(max_features = 'sqrt', max_leaf_nodes = 5), SGDClassifier(max_iter = 200, tol = None), MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)]\n",
    "\n",
    "for model in modelList:\n",
    "    model.fit(x_train, y_train)\n",
    "    y_train_pred = Apply_model(model, x_train, y_train)\n",
    "    print(x_train.shape)\n",
    "    plt.figure()\n",
    "    Confuse(y_train, y_train_pred, classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model in modelList:\n",
    "    y_test_pred = Apply_model(model, x_test, y_test)\n",
    "    print(x_test.shape)\n",
    "    plt.figure()\n",
    "    Confuse(y_train, y_train_pred, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA()\n",
    "pcad_data = pca.fit_transform(x_variable)\n",
    "#percentage variation on each principal component\n",
    "per_var = np.round(pca.explained_variance_ratio_ * 100, decimals=1)\n",
    "\n",
    "#create lables for eachb principal component\n",
    "labels = ['PC' + str(pc) for pc in range(1, len(per_var)+1)]\n",
    "labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as  plt\n",
    "%matplotlib inline\n",
    "plt.bar(x = range(1, len(per_var)+1), height = per_var, tick_label = labels)\n",
    "plt.ylabel('Percentage of explained variables')\n",
    "plt.xlabel('Principal Component')\n",
    "plt.title('Screen Plot')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "rf_reg_model = RandomForestRegressor(random_state=1, max_depth=10)\n",
    "sgd_reg_model = SGDRegressor(random_state=1, max_iter=10)\n",
    "\n",
    "rf_reg_model.fit(x_train, y_train)\n",
    "sgd_reg_model.fit(x_train, y_train)\n",
    "\n",
    "important_feat = rf_reg_model.feature_importances_\n",
    "\n",
    "sgd_reg_model.fit(x_train, y_train)\n",
    "# perform permutation importance\n",
    "results = permutation_importance(sgd_reg_model, x_train, y_train, scoring='neg_mean_squared_error')\n",
    "\n",
    "# get importance\n",
    "importance = results.importances_mean.argsort()\n",
    "\n",
    "print(importance)\n",
    "\n",
    "for i,v in enumerate(importance):\n",
    "\tprint('Feature: %0d, Score: %.5f' % (i,v))\n",
    "\n",
    "indices = np.argsort(important_feat)[-15:]  # top 10 features\n",
    "\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), important_feat[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [predictorFeatures[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_fitted_variable = defenders[predictorFeatures[indices]]\n",
    "x_fitted_variable.iloc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "x_fit_train, x_fit_test, y_fit_train, y_fit_test = train_test_split(x_fitted_variable, y_variable, test_size=0.2)\n",
    "print (x_fit_train.shape, y_fit_train.shape)\n",
    "print (x_fit_test.shape, y_fit_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model in modelList:\n",
    "    model.fit(x_fit_train, y_fit_train)\n",
    "    y_train_fit_pred = Apply_model(model, x_fit_train, y_fit_train)\n",
    "    print(x_fit_train.shape)\n",
    "    plt.figure()\n",
    "    Confuse(y_fit_train, y_train_fit_pred, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model in modelList:\n",
    "    y_test_fit_pred = Apply_model(model, x_fit_test, y_fit_test)\n",
    "    print(x_fit_test.shape)\n",
    "    plt.figure()\n",
    "    Confuse(y_fit_test, y_test_fit_pred, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "feature = SelectFromModel(rf_reg_model)\n",
    "RF_fitted_Model_new = feature.fit_transform(X_train, y_train)\n",
    "print(RF_fitted_Model_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}